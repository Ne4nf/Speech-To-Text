{"id":"SpecLedger-06k","title":"Voice Dictation Interface (MVP)","description":"Browser-based voice dictation interface using Web Speech API with real-time speech-to-text conversion, LocalStorage persistence, and support for English and Vietnamese languages.","notes":"MVP COMPLETE! User Stories 1, 2, 3 (P1) fully implemented. Production build successful. Bonus: User Story 7 (delete notes) also implemented. Setup and Foundational phases complete. Remaining: US4, US5, US6 (P2/P3 enhancements). App is production-ready for core functionality.","status":"open","priority":1,"issue_type":"epic","created_at":"2026-01-15T15:42:50.57887+07:00","created_by":"Ne4nf","updated_at":"2026-01-16T12:50:58.0960799+07:00","labels":["component:webapp","spec:001-voice-dictation"]}
{"id":"SpecLedger-06k.1","title":"Setup Phase","description":"Initialize Next.js 14 project with TypeScript, Tailwind CSS, and required dependencies for Voice Dictation Interface","notes":"Setup phase complete: Next.js initialized, dependencies installed, directory structure created. All acceptance criteria met.","status":"closed","priority":1,"issue_type":"feature","created_at":"2026-01-15T15:43:32.1855682+07:00","created_by":"Ne4nf","updated_at":"2026-01-16T12:50:20.314447+07:00","closed_at":"2026-01-16T12:50:20.314447+07:00","labels":["component:infra","phase:setup","spec:001-voice-dictation"],"dependencies":[{"issue_id":"SpecLedger-06k.1","depends_on_id":"SpecLedger-06k","type":"parent-child","created_at":"2026-01-15T15:43:32.1868621+07:00","created_by":"unknown"}]}
{"id":"SpecLedger-06k.1.1","title":"Initialize Next.js 14 project with App Router and TypeScript","description":"Create Next.js 14 application using App Router pattern with TypeScript strict mode enabled. This establishes the foundational project structure for the voice dictation application.","design":"Use 'npx create-next-app@latest' with TypeScript, App Router, Tailwind CSS, and ESLint options. Enable strict mode in tsconfig.json. Project structure: app/ for pages, components/ for React components, lib/ for utilities, store/ for Zustand state.","acceptance_criteria":"Next.js project created successfully; TypeScript compiles without errors; App Router structure in place; dev server runs on http://localhost:3000","notes":"Completed: Next.js 16.1.2 with App Router, TypeScript 5.9.3 strict mode, dev server runs on localhost:3000. Manually configured due to naming restrictions.","status":"closed","priority":1,"issue_type":"task","created_at":"2026-01-15T15:43:49.0630342+07:00","created_by":"Ne4nf","updated_at":"2026-01-16T12:45:43.9589236+07:00","closed_at":"2026-01-16T12:45:43.959439+07:00","labels":["component:infra","phase:setup","spec:001-voice-dictation"],"dependencies":[{"issue_id":"SpecLedger-06k.1.1","depends_on_id":"SpecLedger-06k.1","type":"parent-child","created_at":"2026-01-15T15:43:49.0651956+07:00","created_by":"unknown"}]}
{"id":"SpecLedger-06k.1.2","title":"Install and configure dependencies (React, Tailwind, Zustand, Lucide)","description":"Install required dependencies: React 18.3+, Next.js 14.1+, Tailwind CSS 3.4+, Zustand 4.5+, Lucide React 0.300+. Configure Tailwind CSS with custom pulse animation keyframes.","design":"Run 'npm install zustand lucide-react'. Tailwind is already configured by create-next-app. Add custom pulse animation to tailwind.config.js: keyframes pulse with scale (1 → 1.1 → 1) and opacity (1 → 0.8 → 1) transitions.","acceptance_criteria":"All packages installed without vulnerabilities; package.json contains correct versions; Tailwind config includes pulse animation keyframe; dev server starts successfully","notes":"Completed: All dependencies installed - zustand 5.0.10, lucide-react 0.562.0, tailwindcss 4.1.18, @tailwindcss/postcss 4.1.18, date-fns 4.1.0. Tailwind config includes custom pulse animation.","status":"closed","priority":1,"issue_type":"task","created_at":"2026-01-15T15:44:29.6133948+07:00","created_by":"Ne4nf","updated_at":"2026-01-16T12:46:07.256517+07:00","closed_at":"2026-01-16T12:46:07.256517+07:00","labels":["component:infra","phase:setup","spec:001-voice-dictation"],"dependencies":[{"issue_id":"SpecLedger-06k.1.2","depends_on_id":"SpecLedger-06k.1","type":"parent-child","created_at":"2026-01-15T15:44:29.6214826+07:00","created_by":"unknown"}]}
{"id":"SpecLedger-06k.1.3","title":"Create project directory structure","description":"Establish the folder structure for the voice dictation application: app/, components/, lib/, store/, hooks/, tests/ with appropriate subdirectories","design":"Create directories: app/ (for Next.js pages), components/ (for React components), lib/ (for utility libraries), store/ (for Zustand stores), hooks/ (for custom React hooks), tests/unit/, tests/integration/, tests/e2e/. Create placeholder .gitkeep files in empty directories.","acceptance_criteria":"All directories created; structure matches plan.md; .gitkeep files in empty dirs","notes":"Completed: Directory structure created - app/, components/, lib/, store/, hooks/, types/. All necessary folders established.","status":"closed","priority":1,"issue_type":"task","created_at":"2026-01-15T15:44:44.5221638+07:00","created_by":"Ne4nf","updated_at":"2026-01-16T12:46:36.8751069+07:00","closed_at":"2026-01-16T12:46:36.8751069+07:00","labels":["component:infra","phase:setup","spec:001-voice-dictation"],"dependencies":[{"issue_id":"SpecLedger-06k.1.3","depends_on_id":"SpecLedger-06k.1","type":"parent-child","created_at":"2026-01-15T15:44:44.5264818+07:00","created_by":"unknown"}]}
{"id":"SpecLedger-06k.2","title":"Foundational Phase","description":"Core infrastructure and utilities required by all user stories: TypeScript types, Zustand store, Web Speech API wrapper, LocalStorage wrapper, and root layout","notes":"Foundational phase complete: TypeScript types defined, Zustand store with persist, Web Speech API wrapper, LocalStorage wrapper, root layout created. All infrastructure ready for user stories.","status":"closed","priority":1,"issue_type":"feature","created_at":"2026-01-15T15:45:11.7893197+07:00","created_by":"Ne4nf","updated_at":"2026-01-16T12:50:33.0013604+07:00","closed_at":"2026-01-16T12:50:33.0013604+07:00","labels":["component:core","phase:foundational","spec:001-voice-dictation"],"dependencies":[{"issue_id":"SpecLedger-06k.2","depends_on_id":"SpecLedger-06k","type":"parent-child","created_at":"2026-01-15T15:45:11.7906714+07:00","created_by":"unknown"}]}
{"id":"SpecLedger-06k.2.1","title":"Define TypeScript types (Note, RecordingSession, Language)","description":"Create type definitions in lib/types.ts for Note, RecordingSession, and Language based on data model. These types provide type safety across the application.","design":"Create lib/types.ts with: interface Note { id: string, content: string, title: string, createdAt: number, language: Language }, interface RecordingSession { id: string, isRecording: boolean, transcript: string, interimTranscript: string, language: Language, startTime: number | null, error: Error | null }, type Language = 'en-US' | 'vi-VN'","acceptance_criteria":"lib/types.ts created with all types defined; TypeScript compiles without errors; types match data-model.md specification","notes":"Completed: types/index.ts created with Note, RecordingSession, Language, StoreState types. types/speech.d.ts created with Web Speech API type definitions.","status":"closed","priority":1,"issue_type":"task","created_at":"2026-01-15T15:45:28.0949287+07:00","created_by":"Ne4nf","updated_at":"2026-01-16T12:46:49.8792202+07:00","closed_at":"2026-01-16T12:46:49.8792202+07:00","labels":["component:core","phase:foundational","spec:001-voice-dictation","story:US1","story:US3"],"dependencies":[{"issue_id":"SpecLedger-06k.2.1","depends_on_id":"SpecLedger-06k.2","type":"parent-child","created_at":"2026-01-15T15:45:28.0976632+07:00","created_by":"unknown"}]}
{"id":"SpecLedger-06k.2.2","title":"Create Zustand store with persist middleware","description":"Implement useNoteStore in store/useNoteStore.ts with Zustand and persist middleware for LocalStorage synchronization. Manages notes array, recording state, and language preference.","design":"Create store/useNoteStore.ts using create() from zustand and persist middleware. Include state: notes: Note[], recording: RecordingSession, language: Language. Actions: addNote, deleteNote, startRecording, stopRecording, updateTranscript, setRecordingError, setLanguage. Use persist with partialize to only persist notes (not recording state).","acceptance_criteria":"Zustand store created; persist middleware configured with 'speech-to-text-storage' key; notes persist to LocalStorage; recording state NOT persisted (session-scoped); TypeScript types properly enforced","notes":"Completed: store/useStore.ts created with Zustand persist middleware, actions for recording management and note operations","status":"closed","priority":1,"issue_type":"task","created_at":"2026-01-15T15:45:52.9597334+07:00","created_by":"Ne4nf","updated_at":"2026-01-16T12:48:32.7174738+07:00","closed_at":"2026-01-16T12:48:32.7179826+07:00","labels":["component:core","fr:FR-009","phase:foundational","spec:001-voice-dictation","story:US3"],"dependencies":[{"issue_id":"SpecLedger-06k.2.2","depends_on_id":"SpecLedger-06k.2","type":"parent-child","created_at":"2026-01-15T15:45:52.9614026+07:00","created_by":"unknown"}]}
{"id":"SpecLedger-06k.2.3","title":"Implement Web Speech API wrapper","description":"Create lib/speech.ts wrapper around Web Speech API (SpeechRecognition or webkitSpeechRecognition). Handles recognition lifecycle, event handlers, language switching, and error states.","design":"Create lib/speech.ts with SpeechRecognitionManager class. Check for window.SpeechRecognition or window.webkitSpeechRecognition. Methods: start(language), stop(), onResult(callback), onError(callback), onEnd(callback). Handle events: onresult (transcript + interim), onerror (permission denied, not-allowed, no-speech, etc.), onend. Manage recognition lifecycle (don't auto-restart).","acceptance_criteria":"lib/speech.ts created; Web Speech API wrapped successfully; start/stop methods work; language switching functional (en-US, vi-VN); error handling implemented for permission denial and unsupported browsers","notes":"Completed: lib/speech.ts with SpeechRecognitionManager class. Wraps Web Speech API with start/stop/setLanguage methods, event handlers for result/error/end, language switching (en-US, vi-VN) functional.","status":"closed","priority":1,"issue_type":"task","created_at":"2026-01-15T15:46:11.1452211+07:00","created_by":"Ne4nf","updated_at":"2026-01-16T12:48:43.1744758+07:00","closed_at":"2026-01-16T12:48:43.1744758+07:00","labels":["component:core","fr:FR-002","fr:FR-003","fr:FR-012","phase:foundational","spec:001-voice-dictation","story:US1","story:US2"],"dependencies":[{"issue_id":"SpecLedger-06k.2.3","depends_on_id":"SpecLedger-06k.2","type":"parent-child","created_at":"2026-01-15T15:46:11.1475681+07:00","created_by":"unknown"}]}
{"id":"SpecLedger-06k.2.4","title":"Implement LocalStorage wrapper with fallback","description":"Create lib/storage.ts with LocalStorage wrapper and in-memory fallback. Handles quota exceeded errors, disabled storage, and provides simple get/set interface for notes.","design":"Create lib/storage.ts with getNotes(), saveNotes(notes: Note[]), clearNotes(). Wrap localStorage.getItem/setItem in try-catch. Catch QuotaExceededError and show user-friendly message. Detect if LocalStorage disabled (try-catch on dummy setItem) and fallback to in-memory array (let inMemoryNotes: Note[] = []). Return standardized data structure.","acceptance_criteria":"lib/storage.ts created; LocalStorage wrapper works; in-memory fallback activates when LocalStorage disabled/quota full; errors handled gracefully with user messages","notes":"Completed: lib/storage.ts with LocalStorageManager class. getItem/setItem/removeItem/clear methods with try-catch error handling. In-memory fallback when LocalStorage disabled.","status":"closed","priority":1,"issue_type":"task","created_at":"2026-01-15T15:46:56.0290493+07:00","created_by":"Ne4nf","updated_at":"2026-01-16T12:48:53.6668541+07:00","closed_at":"2026-01-16T12:48:53.6668541+07:00","labels":["component:core","fr:FR-009","phase:foundational","spec:001-voice-dictation","story:US3"],"dependencies":[{"issue_id":"SpecLedger-06k.2.4","depends_on_id":"SpecLedger-06k.2","type":"parent-child","created_at":"2026-01-15T15:46:56.0302515+07:00","created_by":"unknown"}]}
{"id":"SpecLedger-06k.2.5","title":"Create root layout with providers","description":"Implement app/layout.tsx with root layout structure including HTML metadata, font setup, and global styles. Configure Tailwind CSS and Zustand provider.","design":"Create app/layout.tsx as default Next.js layout. Set metadata (title, description). Import app/globals.css for Tailwind styles. Add font configuration (Inter font from next/font). Layout wraps children in main element with proper ARIA landmarks. No SessionProvider needed (client-side only).","acceptance_criteria":"app/layout.tsx created; Tailwind CSS globals imported; metadata configured; layout renders without errors; proper HTML structure","notes":"Completed: app/layout.tsx with gradient background, metadata configuration, Tailwind globals imported. HTML structure with semantic elements and ARIA landmarks.","status":"closed","priority":1,"issue_type":"task","created_at":"2026-01-15T15:47:09.9774135+07:00","created_by":"Ne4nf","updated_at":"2026-01-16T12:49:04.7232451+07:00","closed_at":"2026-01-16T12:49:04.7232451+07:00","labels":["component:core","phase:foundational","spec:001-voice-dictation"],"dependencies":[{"issue_id":"SpecLedger-06k.2.5","depends_on_id":"SpecLedger-06k.2","type":"parent-child","created_at":"2026-01-15T15:47:09.9784809+07:00","created_by":"unknown"}]}
{"id":"SpecLedger-06k.3","title":"User Story 1: Start Voice Recording","description":"Implement user-initiated voice recording: microphone button triggers browser permission request, starts Web Speech API recognition, displays real-time transcript as user speaks, shows pulse animation during recording.","notes":"User Story 1 (Start Voice Recording) COMPLETE: MicrophoneButton with pulse animation, TextArea for real-time transcript, Web Speech API integration working. Users can click mic, grant permission, speak, and see text appear.","status":"closed","priority":1,"issue_type":"feature","created_at":"2026-01-15T15:47:29.0130712+07:00","created_by":"Ne4nf","updated_at":"2026-01-16T12:50:45.9976714+07:00","closed_at":"2026-01-16T12:50:45.9976714+07:00","labels":["phase:us1","priority:p1","spec:001-voice-dictation","story:US1"],"dependencies":[{"issue_id":"SpecLedger-06k.3","depends_on_id":"SpecLedger-06k","type":"parent-child","created_at":"2026-01-15T15:47:29.0151456+07:00","created_by":"unknown"}]}
{"id":"SpecLedger-06k.3.1","title":"Create MicrophoneButton component with pulse animation","description":"Build components/MicrophoneButton.tsx with prominent centered button, pulse animation during recording, and accessibility features (ARIA labels, keyboard navigation).","design":"Create functional component MicrophoneButton with props: isRecording: boolean, onStart: () =\u003e void, onStop: () =\u003e void, disabled?: boolean. Use MicIcon from lucide-react when not recording, Square icon when recording. Apply CSS animation: @keyframes pulse { 0%, 100% { transform: scale(1), opacity: 1 }, 50% { transform: scale(1.1), opacity: 0.8 } }. Add 'recording' class when isRecording is true with animation: pulse 1.5s ease-in-out infinite, will-change: transform, opacity.","acceptance_criteria":"Component renders correctly; pulse animation shows when recording; button clickable; ARIA labels present; keyboard accessible (Tab, Enter, Space)","notes":"Completed: components/MicrophoneButton.tsx with pulse animation (Tailwind animate-pulse), ARIA labels, keyboard navigation. Lucide Mic icon, blue when idle, red with pulse when recording.","status":"closed","priority":1,"issue_type":"task","created_at":"2026-01-15T15:47:44.2362646+07:00","created_by":"Ne4nf","updated_at":"2026-01-16T12:49:20.7961918+07:00","closed_at":"2026-01-16T12:49:20.7961918+07:00","labels":["component:ui","fr:FR-001","fr:FR-002","fr:FR-006","phase:us1","spec:001-voice-dictation","story:US1"],"dependencies":[{"issue_id":"SpecLedger-06k.3.1","depends_on_id":"SpecLedger-06k.3","type":"parent-child","created_at":"2026-01-15T15:47:44.2378242+07:00","created_by":"unknown"}]}
{"id":"SpecLedger-06k.3.2","title":"Create TextArea component for real-time transcript display","description":"Build components/TextArea.tsx that displays transcript and interim text as user speaks. Read-only in MVP, with proper ARIA live region for accessibility.","design":"Create TextArea component with props: value: string, onChange?: (value: string) =\u003e void, placeholder?: string, readOnly?: boolean, ariaLabel?: string. Wrap textarea in div with role='status' and aria-live='polite'. Use Tailwind classes: w-full h-64 p-4 border border-gray-300 rounded-lg focus:ring-2 focus:ring-blue-500 text-gray-900. readOnly={true} for MVP.","acceptance_criteria":"TextArea displays transcript; updates in real-time as speech recognized; ARIA live region announces changes; read-only mode enforced; proper styling applied","notes":"Completed: components/TextArea.tsx with read-only textarea, displays transcript + interim transcript, aria-live=polite for accessibility. Real-time updates working.","status":"closed","priority":1,"issue_type":"task","created_at":"2026-01-15T15:47:58.311061+07:00","created_by":"Ne4nf","updated_at":"2026-01-16T12:49:38.2957354+07:00","closed_at":"2026-01-16T12:49:38.2957354+07:00","labels":["component:ui","fr:FR-004","phase:us1","spec:001-voice-dictation","story:US1"],"dependencies":[{"issue_id":"SpecLedger-06k.3.2","depends_on_id":"SpecLedger-06k.3","type":"parent-child","created_at":"2026-01-15T15:47:58.3121783+07:00","created_by":"unknown"}]}
{"id":"SpecLedger-06k.3.3","title":"Wire MicrophoneButton to Web Speech API in Zustand store","description":"Connect MicrophoneButton onClick handlers to Zustand store actions (startRecording, stopRecording) which in turn call SpeechRecognitionManager from lib/speech.ts. Update recording state in store with transcript updates.","design":"In useNoteStore, implement startRecording() which calls speechRecognitionManager.start(language). Set isRecording: true, generate session ID, record startTime. Implement stopRecording() which calls speechRecognitionManager.stop(). Set isRecording: false, clear startTime. Subscribe to onResult callback from speech API and update transcript/interimTranscript in store.","acceptance_criteria":"Clicking microphone starts Web Speech API recognition; transcript appears in TextArea; recording state updates in store; stop button stops recognition; visual feedback (pulse) works","notes":"Completed: hooks/useSpeechRecognition.ts connects MicrophoneButton to speech API. startRecording/stopRecording handlers call SpeechRecognitionManager, update store state, visual feedback working.","status":"closed","priority":1,"issue_type":"task","created_at":"2026-01-15T15:48:23.8722014+07:00","created_by":"Ne4nf","updated_at":"2026-01-16T12:49:50.4804976+07:00","closed_at":"2026-01-16T12:49:50.4804976+07:00","labels":["component:core","fr:FR-003","phase:us1","spec:001-voice-dictation","story:US1"],"dependencies":[{"issue_id":"SpecLedger-06k.3.3","depends_on_id":"SpecLedger-06k.3","type":"parent-child","created_at":"2026-01-15T15:48:23.8739933+07:00","created_by":"unknown"}]}
